{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40dc5a9f-a8e6-4889-a0c9-b16f82589dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1060f167-f64b-48ef-af15-afb534270afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_box_object_scenarios(n, num_boxes, num_objects, num_transitions):\n",
    "    \"\"\"\n",
    "    Generate scenarios about objects in boxes with transitions.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of scenarios to generate\n",
    "        num_boxes: Number of boxes in each scenario\n",
    "        num_objects: Number of objects in each scenario\n",
    "        num_transitions: Number of transitions (moves) in each scenario\n",
    "    \n",
    "    Returns:\n",
    "        A list of tuples, each containing (scenario_text, answer)\n",
    "    \"\"\"\n",
    "    # Generate box and object names\n",
    "    box_names = [f\"Box {chr(65 + i)}\" for i in range(num_boxes)]  # Box A, Box B, etc.\n",
    "    object_names = [\"hat\", \"glove\", \"ball\", \"key\", \"pen\", \"book\", \"coin\", \"card\", \"ring\", \"watch\"]\n",
    "    \n",
    "    if num_objects > len(object_names):\n",
    "        raise ValueError(f\"Set a smaller num_objects: {num_objects}\")\n",
    "    else:\n",
    "        # Use only the required number of objects\n",
    "        object_names = object_names[:num_objects]\n",
    "    \n",
    "    scenarios = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Create a dictionary to track which objects are in which boxes\n",
    "        box_contents = {box: [] for box in box_names}\n",
    "        \n",
    "        # Initial random placement of objects in boxes\n",
    "        available_objects = object_names.copy()\n",
    "        for obj in available_objects:\n",
    "            box = random.choice(box_names)\n",
    "            box_contents[box].append(obj)\n",
    "        \n",
    "        # Generate the scenario text\n",
    "        scenario_text = []\n",
    "        \n",
    "        # Initial state description\n",
    "        for box in box_names:\n",
    "            for obj in box_contents[box]:\n",
    "                scenario_text.append(f\"{box} contains the {obj}.\")\n",
    "        \n",
    "        # Generate transitions (moves)\n",
    "        for _ in range(num_transitions):\n",
    "            # Choose a random source box that has objects\n",
    "            source_boxes = [box for box in box_names if box_contents[box]]\n",
    "            if not source_boxes:\n",
    "                break\n",
    "            source_box = random.choice(source_boxes)\n",
    "            \n",
    "            # Choose a random object from the source box\n",
    "            obj = random.choice(box_contents[source_box])\n",
    "            \n",
    "            # Choose a random destination box different from the source\n",
    "            dest_boxes = [box for box in box_names if box != source_box]\n",
    "            dest_box = random.choice(dest_boxes)\n",
    "            \n",
    "            # Move the object\n",
    "            box_contents[source_box].remove(obj)\n",
    "            box_contents[dest_box].append(obj)\n",
    "            \n",
    "            # Add the move to the scenario text\n",
    "            scenario_text.append(f\"Move the {obj} into {dest_box}.\")\n",
    "        \n",
    "        # Select a random object for the question\n",
    "        all_objects_in_boxes = [(obj, box) for box in box_names for obj in box_contents[box]]\n",
    "        if all_objects_in_boxes:\n",
    "            question_obj, question_box = random.choice(all_objects_in_boxes)\n",
    "            \n",
    "            # Create the question and answer\n",
    "            question = f\"{question_obj.capitalize()} is in the Box\"\n",
    "            answer = ' '+ question_box.split()[1]  # Extract just the letter part (A, B, etc.)\n",
    "            \n",
    "            # Combine all text into one scenario\n",
    "            full_scenario = \" \".join(scenario_text) + \" \" + question\n",
    "            scenarios.append((full_scenario, answer))\n",
    "    \n",
    "    return scenarios\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8273267b-623e-4614-90f8-23611bb5ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "def evaluate_box_object_task(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    scenarios: List[Tuple[str, str]],\n",
    "    batch_size: int = 10,\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ") -> float:\n",
    "    \"\"\"Evaluate model accuracy on box-object task\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_scenarios = len(scenarios)\n",
    "    if not tokenizer.pad_token: \n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    prompts = [s[0] for s in scenarios]\n",
    "    answers = [s[1] for s in scenarios]\n",
    "\n",
    "    prompt_tokens = tokenizer(prompts, padding=True, padding_side=\"left\", return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    answer_tokens = tokenizer(answers, padding=True, padding_side=\"right\", add_special_tokens=False, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "\n",
    "    for i in range(0, total_scenarios, batch_size): \n",
    "        batch_prompt_tokens = prompt_tokens[i: i+batch_size]\n",
    "        batch_answer_tokens = answer_tokens[i: i+batch_size].squeeze()\n",
    "\n",
    "\n",
    "        last_token_logits = model(batch_prompt_tokens).logits[:, -1, :] \n",
    "        predicted_token_ids = torch.argmax(last_token_logits, dim=1)\n",
    "\n",
    "        matches = (predicted_token_ids == batch_answer_tokens)\n",
    "        correct_predictions += matches.sum().item()\n",
    "\n",
    "    return correct_predictions / total_scenarios\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799943b0-5c08-40fa-b3b5-afeb65659f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def scan_model_accuracy(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    box_range=(2, 6),\n",
    "    transition_range=(1, 6),\n",
    "    num_samples=50,\n",
    "    num_objects=None,\n",
    "    batch_size=10,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "):\n",
    "    \"\"\"Scan model accuracy across different configurations\"\"\"\n",
    "    num_box_values = range(box_range[0], box_range[1] + 1)\n",
    "    num_transition_values = range(transition_range[0], transition_range[1] + 1)\n",
    "    \n",
    "    results = np.zeros((len(num_transition_values), len(num_box_values)))\n",
    "    \n",
    "    for i, num_transitions in enumerate(tqdm(num_transition_values, desc=\"Transitions\")):\n",
    "        for j, num_boxes in enumerate(tqdm(num_box_values, desc=\"Boxes\", leave=False)):\n",
    "            num_objs = num_objects if num_objects is not None else num_boxes\n",
    "            \n",
    "            scenarios = generate_box_object_scenarios(\n",
    "                n=num_samples, \n",
    "                num_boxes=num_boxes, \n",
    "                num_objects=num_objs,\n",
    "                num_transitions=num_transitions\n",
    "            )\n",
    "            accuracy = evaluate_box_object_task(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                scenarios=scenarios,\n",
    "                batch_size=batch_size,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            results[i, j] = accuracy * 100\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    cmap = plt.cm.Blues\n",
    "    cmap.set_bad('white', 1.0)\n",
    "    \n",
    "    heatmap = plt.imshow(\n",
    "        results,\n",
    "        cmap=cmap,\n",
    "        aspect='equal',\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        origin='lower'\n",
    "    )\n",
    "    \n",
    "    plt.xticks(np.arange(len(num_box_values)), num_box_values)\n",
    "    plt.yticks(np.arange(len(num_transition_values)), num_transition_values)\n",
    "    plt.xlabel('Number of Boxes')\n",
    "    plt.ylabel('Number of Transitions')\n",
    "    \n",
    "    cbar = plt.colorbar(heatmap)  # Fixed: create colorbar variable\n",
    "    cbar.set_label('Accuracy (%)')\n",
    "    \n",
    "    for i in range(len(num_transition_values)):\n",
    "        for j in range(len(num_box_values)):\n",
    "            accuracy = results[i, j]\n",
    "            if accuracy > 0:\n",
    "                plt.text(\n",
    "                    j, i, \n",
    "                    f\"{accuracy:.0f}%\", \n",
    "                    ha=\"center\", \n",
    "                    va=\"center\", \n",
    "                    color=\"black\" if accuracy < 70 else \"white\",\n",
    "                    fontweight='bold'\n",
    "                )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, results  # Return fig explicitly instead of plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b0be1f-2280-4e76-86e6-234a372f4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "219fbcae-d807-4ade-baff-8d60d73a2a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transitions:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:03,  2.30it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:00<00:03,  2.25it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:01<00:02,  2.22it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:01<00:02,  2.16it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:02<00:01,  2.03it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:02<00:01,  1.86it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:03<00:01,  1.72it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:04<00:00,  1.59it/s]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:05<00:00,  1.48it/s]\n",
      "Transitions:  10%|█         | 1/10 [00:05<00:46,  5.18s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:03,  2.22it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:00<00:03,  2.19it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:01<00:02,  2.14it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:01<00:02,  1.99it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:02<00:02,  1.83it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:03<00:01,  1.69it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:04<00:01,  1.56it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:04<00:00,  1.45it/s]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:05<00:00,  1.36it/s]\n",
      "Transitions:  20%|██        | 2/10 [00:10<00:43,  5.45s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:03,  2.14it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:00<00:03,  1.98it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:01<00:03,  1.89it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:02<00:02,  1.75it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:02<00:02,  1.64it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:03<00:01,  1.52it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:04<00:01,  1.42it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:05<00:00,  1.33it/s]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:06<00:00,  1.26it/s]\n",
      "Transitions:  30%|███       | 3/10 [00:16<00:40,  5.77s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:04,  1.88it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:04,  1.73it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:01<00:03,  1.62it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:02<00:03,  1.55it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:03<00:02,  1.46it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:04<00:02,  1.38it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:04<00:01,  1.31it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:05<00:00,  1.24it/s]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:06<00:00,  1.16it/s]\n",
      "Transitions:  40%|████      | 4/10 [00:23<00:37,  6.17s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:04,  1.63it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:04,  1.55it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:02<00:04,  1.46it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:02<00:03,  1.38it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:03<00:03,  1.31it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:04<00:02,  1.25it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:05<00:01,  1.20it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:06<00:00,  1.13it/s]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:07<00:00,  1.07it/s]\n",
      "Transitions:  50%|█████     | 5/10 [00:31<00:33,  6.64s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:05,  1.48it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:05,  1.40it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:02<00:04,  1.33it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:03<00:03,  1.27it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:03<00:03,  1.22it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:04<00:02,  1.14it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:05<00:01,  1.09it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:06<00:00,  1.04it/s]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:08<00:00,  1.01s/it]\n",
      "Transitions:  60%|██████    | 6/10 [00:39<00:28,  7.14s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:06,  1.33it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:05,  1.29it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:02<00:04,  1.23it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:03<00:04,  1.19it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:04<00:03,  1.11it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:05<00:02,  1.06it/s]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:06<00:01,  1.01it/s]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:07<00:01,  1.04s/it]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:08<00:00,  1.08s/it]\n",
      "Transitions:  70%|███████   | 7/10 [00:48<00:22,  7.65s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:06,  1.25it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:05,  1.20it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:02<00:05,  1.16it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:03<00:04,  1.09it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:04<00:03,  1.04it/s]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:05<00:03,  1.01s/it]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:06<00:02,  1.05s/it]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:08<00:01,  1.12s/it]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:09<00:00,  1.17s/it]\n",
      "Transitions:  80%|████████  | 8/10 [00:57<00:16,  8.21s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:06,  1.16it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:06,  1.13it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:02<00:05,  1.06it/s]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:03<00:04,  1.01it/s]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:04<00:04,  1.03s/it]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:06<00:03,  1.07s/it]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:07<00:02,  1.13s/it]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:08<00:01,  1.19s/it]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:10<00:00,  1.25s/it]\n",
      "Transitions:  90%|█████████ | 9/10 [01:07<00:08,  8.79s/it]\n",
      "\u001b[Aes:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "\u001b[Aes:  11%|█         | 1/9 [00:00<00:07,  1.10it/s]\n",
      "\u001b[Aes:  22%|██▏       | 2/9 [00:01<00:06,  1.03it/s]\n",
      "\u001b[Aes:  33%|███▎      | 3/9 [00:03<00:06,  1.10s/it]\n",
      "\u001b[Aes:  44%|████▍     | 4/9 [00:04<00:05,  1.10s/it]\n",
      "\u001b[Aes:  56%|█████▌    | 5/9 [00:05<00:04,  1.12s/it]\n",
      "\u001b[Aes:  67%|██████▋   | 6/9 [00:06<00:03,  1.17s/it]\n",
      "\u001b[Aes:  78%|███████▊  | 7/9 [00:08<00:02,  1.22s/it]\n",
      "\u001b[Aes:  89%|████████▉ | 8/9 [00:09<00:01,  1.28s/it]\n",
      "\u001b[Aes: 100%|██████████| 9/9 [00:10<00:00,  1.34s/it]\n",
      "Transitions: 100%|██████████| 10/10 [01:18<00:00,  7.84s/it]\n"
     ]
    }
   ],
   "source": [
    "fig, results = scan_model_accuracy(model, tokenizer, box_range=(2, 10), transition_range=(1, 10), num_samples=500)\n",
    "fig.savefig('gpt2-box.png', dpi=1000, bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afacc74-e9b3-4de5-b406-386c91578a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
